{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn \n",
    "import numpy as np \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_feature = pd.read_csv('../Dataset/Murni/processed_dataset_10.csv',sep=',')\n",
    "df_chi_square = pd.read_csv('../Dataset/Murni/processed_dataset_chi_square.csv', sep=',')\n",
    "df_feature_selection = pd.read_csv('../Dataset/Murni/processed_dataset_5.csv',sep=',')\n",
    "df_slice = pd.read_csv('../Dataset/Murni/processed_dataset_slice.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>pktrate</th>\n",
       "      <th>pktperflow</th>\n",
       "      <th>dur</th>\n",
       "      <th>dur_nsec</th>\n",
       "      <th>bytecount</th>\n",
       "      <th>pktcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>983</td>\n",
       "      <td>235000000</td>\n",
       "      <td>94178</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>511</td>\n",
       "      <td>15344</td>\n",
       "      <td>384</td>\n",
       "      <td>114000000</td>\n",
       "      <td>11954682</td>\n",
       "      <td>221383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>821</td>\n",
       "      <td>243000000</td>\n",
       "      <td>78498</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>330</td>\n",
       "      <td>9919</td>\n",
       "      <td>98</td>\n",
       "      <td>622000000</td>\n",
       "      <td>2145912</td>\n",
       "      <td>32512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>274</td>\n",
       "      <td>8223</td>\n",
       "      <td>287</td>\n",
       "      <td>579000000</td>\n",
       "      <td>90935340</td>\n",
       "      <td>87270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src   dst  Protocol  pktrate  pktperflow  dur   dur_nsec  bytecount  \\\n",
       "0   1.0  11.0         1        0          29  983  235000000      94178   \n",
       "1   6.0  12.0         2      511       15344  384  114000000   11954682   \n",
       "2  10.0  15.0         1        1          30  821  243000000      78498   \n",
       "3  15.0  16.0         2      330        9919   98  622000000    2145912   \n",
       "4   2.0  11.0         3      274        8223  287  579000000   90935340   \n",
       "\n",
       "   pktcount  \n",
       "0       961  \n",
       "1    221383  \n",
       "2       801  \n",
       "3     32512  \n",
       "4     87270  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Full Feature\n",
    "full_feature_x = df_full_feature[df_full_feature.columns[:9]]\n",
    "full_feature_y = df_full_feature['label']\n",
    "\n",
    "full_feature_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst</th>\n",
       "      <th>src</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>pktcount</th>\n",
       "      <th>pktcount.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>221383</td>\n",
       "      <td>221383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>801</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32512</td>\n",
       "      <td>32512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>87270</td>\n",
       "      <td>87270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dst   src  Protocol  pktcount  pktcount.1\n",
       "0  11.0   1.0         1       961         961\n",
       "1  12.0   6.0         2    221383      221383\n",
       "2  15.0  10.0         1       801         801\n",
       "3  16.0  15.0         2     32512       32512\n",
       "4  11.0   2.0         3     87270       87270"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Chi Square \n",
    "chi_square_x = df_chi_square[df_chi_square.columns[:5]]\n",
    "chi_square_y = df_chi_square['label']\n",
    "\n",
    "chi_square_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pktrate</th>\n",
       "      <th>pktperflow</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>511</td>\n",
       "      <td>15344</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330</td>\n",
       "      <td>9919</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>274</td>\n",
       "      <td>8223</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pktrate  pktperflow  Protocol   src   dst\n",
       "0        0          29         1   1.0  11.0\n",
       "1      511       15344         2   6.0  12.0\n",
       "2        1          30         1  10.0  15.0\n",
       "3      330        9919         2  15.0  16.0\n",
       "4      274        8223         3   2.0  11.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Feature Selection\n",
    "feature_selection_x = df_feature_selection[df_feature_selection.columns[:5]]\n",
    "feature_selection_y = df_feature_selection['label']\n",
    "\n",
    "feature_selection_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst</th>\n",
       "      <th>src</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>bytecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>94178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11954682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>78498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2145912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>90935340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dst   src  Protocol  bytecount\n",
       "0  11.0   1.0         1      94178\n",
       "1  12.0   6.0         2   11954682\n",
       "2  15.0  10.0         1      78498\n",
       "3  16.0  15.0         2    2145912\n",
       "4  11.0   2.0         3   90935340"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Slice\n",
    "slice_x = df_slice[df_slice.columns[:4]]\n",
    "slice_y= df_slice['label']\n",
    "\n",
    "slice_x.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perlu untuk dilakukan diskretisasi karena nilai continous mengurangi performansi dari Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(feature_selection_x,feature_selection_y,test_size=0.30,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "nb_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = nb_classifier.predict(x_train)\n",
    "y_pred_test = nb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30910     0]\n",
      " [19630     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76     30910\n",
      "         1.0       0.00      0.00      0.00     19630\n",
      "\n",
      "    accuracy                           0.61     50540\n",
      "   macro avg       0.31      0.50      0.38     50540\n",
      "weighted avg       0.37      0.61      0.46     50540\n",
      "\n",
      "Accuracy: 61.1594776414721\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Accuracy:\",accuracy_score(y_train, y_pred_train)*100)\n",
    "print(\"Precision:\", precision_score(y_train, y_pred_train)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13109     0]\n",
      " [ 8552     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.75     13109\n",
      "         1.0       0.00      0.00      0.00      8552\n",
      "\n",
      "    accuracy                           0.61     21661\n",
      "   macro avg       0.30      0.50      0.38     21661\n",
      "weighted avg       0.37      0.61      0.46     21661\n",
      "\n",
      "Accuracy: 60.518904944370064\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "y_pred_test = [np.argmax(element) for element in y_pred_test]\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=1.645190587753664e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:  4.7min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=1000)\n",
    "}\n",
    "\n",
    "NB_Feature_Grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, scoring='accuracy' ,verbose=1, cv=10, n_jobs=1)\n",
    "NB_Feature_Grid.fit(x_train, y_train)\n",
    "print(NB_Feature_Grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7994459833795013\n"
     ]
    }
   ],
   "source": [
    "print(NB_Feature_Grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=1.645190587753664e-05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = NB_Feature_Grid.best_estimator_\n",
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_full.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Best Estimator \n",
    "joblib.dump(best_estimator, 'naive_bayes_full.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(slice_x,slice_y,test_size=0.20,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier_slice = GaussianNB()\n",
    "nb_classifier_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier_slice.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = nb_classifier_slice.predict(x_train)\n",
    "y_pred_test = nb_classifier_slice.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35241     0]\n",
      " [22519     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76     35241\n",
      "         1.0       0.00      0.00      0.00     22519\n",
      "\n",
      "    accuracy                           0.61     57760\n",
      "   macro avg       0.31      0.50      0.38     57760\n",
      "weighted avg       0.37      0.61      0.46     57760\n",
      "\n",
      "Accuracy: 61.01281163434903\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "y_pred_train = [np.argmax(element) for element in y_pred_train]\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Accuracy:\",accuracy_score(y_train, y_pred_train)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8778    0]\n",
      " [5663    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76      8778\n",
      "         1.0       0.00      0.00      0.00      5663\n",
      "\n",
      "    accuracy                           0.61     14441\n",
      "   macro avg       0.30      0.50      0.38     14441\n",
      "weighted avg       0.37      0.61      0.46     14441\n",
      "\n",
      "Accuracy: 60.78526417838099\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "y_pred_test = [np.argmax(element) for element in y_pred_test]\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=0.05711586478126432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=1000)\n",
    "}\n",
    "\n",
    "NB_Slice_Grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, scoring='accuracy' ,verbose=1, cv=10, n_jobs=1)\n",
    "NB_Slice_Grid.fit(x_train, y_train)\n",
    "print(NB_Slice_Grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6502423822714681\n"
     ]
    }
   ],
   "source": [
    "print(NB_Slice_Grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=0.05711586478126432)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = NB_Slice_Grid.best_estimator_\n",
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_slice.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Best Estimator \n",
    "joblib.dump(best_estimator, 'naive_bayes_slice.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(chi_square_x,chi_square_y,test_size=0.30,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier_chi = GaussianNB()\n",
    "nb_classifier_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier_chi.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = nb_classifier_chi.predict(x_train)\n",
    "y_pred_test = nb_classifier_chi.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30789     0]\n",
      " [19751     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76     30789\n",
      "         1.0       0.00      0.00      0.00     19751\n",
      "\n",
      "    accuracy                           0.61     50540\n",
      "   macro avg       0.30      0.50      0.38     50540\n",
      "weighted avg       0.37      0.61      0.46     50540\n",
      "\n",
      "Accuracy: 60.9200633161852\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "y_pred_train = [np.argmax(element) for element in y_pred_train]\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Accuracy:\",accuracy_score(y_train, y_pred_train)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13230     0]\n",
      " [ 8431     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76     13230\n",
      "         1.0       0.00      0.00      0.00      8431\n",
      "\n",
      "    accuracy                           0.61     21661\n",
      "   macro avg       0.31      0.50      0.38     21661\n",
      "weighted avg       0.37      0.61      0.46     21661\n",
      "\n",
      "Accuracy: 61.07751258021329\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "y_pred_test = [np.argmax(element) for element in y_pred_test]\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=0.4452958509942655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=1000)\n",
    "}\n",
    "\n",
    "NB_Chi_Grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, scoring='accuracy' ,verbose=1, cv=10, n_jobs=1)\n",
    "NB_Chi_Grid.fit(x_train, y_train)\n",
    "print(NB_Chi_Grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6885437277404037\n"
     ]
    }
   ],
   "source": [
    "print(NB_Chi_Grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=0.4452958509942655)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = NB_Chi_Grid.best_estimator_\n",
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_chi.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Best Estimator \n",
    "joblib.dump(best_estimator, 'naive_bayes_chi.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(full_feature_x,full_feature_y,test_size=0.30,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier_full = GaussianNB()\n",
    "nb_classifier_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier_full.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = nb_classifier_full.predict(x_train)\n",
    "y_pred_test = nb_classifier_full.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30789     0]\n",
      " [19751     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76     30789\n",
      "         1.0       0.00      0.00      0.00     19751\n",
      "\n",
      "    accuracy                           0.61     50540\n",
      "   macro avg       0.30      0.50      0.38     50540\n",
      "weighted avg       0.37      0.61      0.46     50540\n",
      "\n",
      "Accuracy: 60.9200633161852\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "y_pred_train = [np.argmax(element) for element in y_pred_train]\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(\"Accuracy:\",accuracy_score(y_train, y_pred_train)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13230     0]\n",
      " [ 8431     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76     13230\n",
      "         1.0       0.00      0.00      0.00      8431\n",
      "\n",
      "    accuracy                           0.61     21661\n",
      "   macro avg       0.31      0.50      0.38     21661\n",
      "weighted avg       0.37      0.61      0.46     21661\n",
      "\n",
      "Accuracy: 61.07751258021329\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "y_pred_test = [np.argmax(element) for element in y_pred_test]\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=2.389892566231053e-09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:  7.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=1000)\n",
    "}\n",
    "\n",
    "NB_Full_Grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, scoring='accuracy' ,verbose=1, cv=10, n_jobs=1)\n",
    "NB_Full_Grid.fit(x_train, y_train)\n",
    "print(NB_Full_Grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6736248516026909\n"
     ]
    }
   ],
   "source": [
    "print(NB_Full_Grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=2.389892566231053e-09)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = NB_Full_Grid.best_estimator_\n",
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_chi.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Best Estimator \n",
    "joblib.dump(best_estimator, 'naive_bayes_chi.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perlu pemilihan fitur kembali karena pointnya masih kurang baik akurasinya, dan belum tahu ketika nanti di kombinasikan dengan LSTM, selain itu perlu mengetahui lagi mengenai Gaussian NB dll"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c2dc7f55a4afb133f9671f18548a683b80d7f864af89313bd9839ac682f147f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
